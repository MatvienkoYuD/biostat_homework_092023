---
title: 'Домашнее задание по курсу "Автоматизация обработки данных"'
subtitle: "Вариант 2"
author: Юлия Матвиенко
output: word_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(stringi)
library(flextable)
library(ggforce)
library(ggbeeswarm)
library(RColorBrewer)
library(ZIR)
library(corrplot)
library(psych)

```

# Чтение данных

В вашем варианте нужно использовать датасет food.

```{r message=FALSE}
data <- read_csv("data/raw/food.csv")
```

# Выведите общее описание данных

```{r}
summary(data)
```

# Очистка данных

1) Уберите переменные, в которых пропущенных значений больше 20% или уберите субъектов со слишком большим количеством пропущенных значений. Или совместите оба варианта. Напишите обоснование, почему вы выбрали тот или иной вариант:

```{r}
sum(is.na(data))
```

**Обоснование**: в анализируемом датасете отсутствуют пропущенные значения.

2) Переименуйте переменные в человекочитаемый вид (что делать с пробелами в названиях?);

3) В соответствии с описанием данных приведите переменные к нужному типу (numeric или factor);

4) Отсортируйте данные по ~~возрасту~~ углеводам по убыванию;

5) Сохраните в файл outliers.csv субъектов, которые являются выбросами (например, по правилу трёх сигм) — это необязательное задание со звёздочкой;

6) Отфильтруйте датасет так, чтобы остались только Rice и Cookie (переменная Category и есть группирующая);

7) Присвойте получившийся датасет переменной "cleaned_data".

```{r}

cleaned_data <- data %>%
  rename_with(function(x) x %>% stri_replace_all_regex(c("Data.", "Major Minerals.", "Vitamins.", "Fat."), c("", "", "", ""), vectorize_all = F)) %>%
  mutate(Category = Category %>% as.factor(),
         `Nutrient Bank Number` = `Nutrient Bank Number` %>% format(scientific = F) %>% as.character()) %>%
  arrange(desc(Carbohydrate)) %>%
  filter(Category %in% c("Rice", "Cookie"))

```

(2) Пробелы в названиях могут присутствовать, потребуется только в дальнейшем оформлять такие названия в апострофы.
 
(3) Переменные Description и Nutrient Bank Number привела к типу character, т.к. это уникальные идентификаторы, и в дальнейшем рассчитывать описательные статистики для этих переменных не имеет смысла.

(5) На мой взгляд в анализируемом датафрейме исключение выбросов нецелесообразно, т.к. наличие таких выбросов обусловлено характеристиками разных видов продуктов, т.е. они являются естественными (какой-то продукт действительно может содержать 0 мг вещества, а другой - 100500 мг). Исключение этих данных, мне кажется, сделает анализ менее точным. Если мое размышление неверное, для сохранения выбросов в отдельный файл предлагаю использовать такой код. Буду благодарна за его проверку :)

```{r eval=FALSE}

outliers_detect <- function(x) {
  Q1 <- quantile(x, probs = 0.25)
  Q3 <- quantile(x, probs = 0.75)
  IQR <- Q3 - Q1
  x > Q3 + IQR * 1.5 | x < Q1 - IQR * 1.5
}

outliers <- cleaned_data[0,]

for (col in 4:ncol(cleaned_data)) {
  out <- cleaned_data[outliers_detect(cleaned_data[[col]]), ]
  outliers <- rbind(outliers, out)
}

outliers <- distinct(outliers)

write_csv(outliers, "data/outliers.csv")
```


# Сколько осталось переменных?

```{r}
ncol(cleaned_data)
```

# Сколько осталось случаев?

```{r}
nrow(cleaned_data)
```

# Есть ли в данных идентичные строки?

```{r}
anyDuplicated(cleaned_data)
```
Идентичных строк нет.

# Сколько всего переменных с пропущенными значениями в данных и сколько пропущенных точек в каждой такой переменной?

```{r}
sum(colSums(is.na(cleaned_data) > 0))
```

# Описательные статистики

## Количественные переменные

1) Рассчитайте для всех количественных переменных для каждой группы (Category):

1.1) Количество значений;

1.2) Количество пропущенных значений;

1.3) Среднее;

1.4) Медиану;

1.5) Стандартное отклонение;

1.6) 25% квантиль и 75% квантиль;

1.7) Интерквартильный размах;

1.8) Минимум;

1.9) Максимум;

1.10) 95% ДИ для среднего - задание со звёздочкой.

```{r}

statistics <- list(
  `Количество значений` = ~length(.x) %>% as.character(),
  `Количество пропущенных значений` = ~sum(is.na(.x)) %>% as.character(),
  `Среднее значение` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", mean(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
  `Медиана` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", median(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
  `Станд. отклон.` = ~ifelse(sum(!is.na(.x)) < 3, "Н/П*", sd(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
  `25% квантиль - 75% квантиль` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", paste0(quantile(.x, 0.25, na.rm = TRUE) %>% round(2), " - ", quantile(.x, 0.75, na.rm = TRUE) %>% round(2)) %>% as.character()),
  `Интерквартильный размах` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", (quantile(.x, 0.75, na.rm = TRUE) - quantile(.x, 0.25, na.rm = TRUE)) %>% round(2) %>% as.character()),
  `Минимум` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", min(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
  `Максимум` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", max(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
  `95% ДИ для среднего` = ~ifelse(sum(!is.na(.x)) < 3, "Н/П*", paste0(t.test(.x, conf.level = 0.95)$conf.int[1] %>% round(2), " - ", t.test(.x, conf.level = 0.95)$conf.int[2] %>% round(2)) %>% as.character())
)

cleaned_data %>%
  select(Category, where(is.numeric)) %>%
  group_by(Category) %>%
  summarize(across(where(is.numeric), statistics)) %>%
  pivot_longer(!Category) %>%
  separate(name, into = c("Переменная", "Статистика"), sep = "_") %>%
  rename(`Значение` = value, `Категория` = Category) %>%
  flextable() %>%
  theme_box() %>%
  merge_v(c("Категория", "Переменная"))

```

## Категориальные переменные

1) Рассчитайте для всех категориальных переменных для каждой группы (Category):

1.1) Абсолютное количество;

1.2) Относительное количество внутри группы;

1.3) 95% ДИ для доли внутри группы - задание со звёздочкой.

```{r}

cleaned_data %>%
  select(Category, where(is.factor)) %>%
  group_by(Category) %>%
  summarise(`Количество` = n(),
            `Процент по выборке` = n() / nrow(cleaned_data) * 100) %>%
  mutate(`Процент по выборке` = `Процент по выборке` %>% round(2) %>% str_c("%")) %>%
  rowwise() %>%
  mutate(`95% ДИ для доли (%)` = paste(round(prop.test(`Количество`, nrow(cleaned_data), conf.level = 0.95, correct = T)$conf.int[1] *100, 2),
                        round(prop.test(`Количество`, nrow(cleaned_data), conf.level = 0.95, correct = T)$conf.int[2] *100, 2),
                        sep = "-")) %>%
  rename(`Категория` = Category) %>%
  flextable() %>%
  theme_box()

```
Единственная факторная переменная в датасете - сама Category. Остальные переменные - или количественные, или строковые.

# Визуализация

## Количественные переменные

1) Для каждой количественной переменной сделайте боксплоты по группам. Расположите их либо на отдельных рисунках, либо на одном, но читаемо;

2) Наложите на боксплоты beeplots - задание со звёздочкой.

3) Раскрасьте боксплоты с помощью библиотеки RColorBrewer.


```{r}

cleaned_data %>%
  select(Category, where(is.numeric)) %>%
  group_by(Category) %>%
  pivot_longer(!Category) %>%
  ggplot(aes(x = Category, y = value, fill = Category)) +
  geom_boxplot() +
  geom_beeswarm(size = 0.5) +
  facet_wrap_paginate(~ name, ncol = 3, nrow = 3, scales = 'free', page = 1) +
  scale_fill_brewer(palette = "Pastel1")
 
cleaned_data %>%
  select(Category, where(is.numeric)) %>%
  group_by(Category) %>%
  pivot_longer(!Category) %>%
  ggplot(aes(x = Category, y = value, fill = Category)) +
  geom_boxplot() +
  geom_beeswarm(size = 0.5) +
  facet_wrap_paginate(~ name, ncol = 3, nrow = 3, scales = 'free', page = 2) +
  scale_fill_brewer(palette = "Pastel1")

cleaned_data %>%
  select(Category, where(is.numeric)) %>%
  group_by(Category) %>%
  pivot_longer(!Category) %>%
  ggplot(aes(x = Category, y = value, fill = Category)) +
  geom_boxplot() +
  geom_beeswarm(size = 0.5) +
  facet_wrap_paginate(~ name, ncol = 3, nrow = 3, scales = 'free', page = 3) +
  scale_fill_brewer(palette = "Pastel1")

cleaned_data %>%
  select(Category, where(is.numeric)) %>%
  group_by(Category) %>%
  pivot_longer(!Category) %>%
  ggplot(aes(x = Category, y = value, fill = Category)) +
  geom_boxplot() +
  geom_beeswarm(size = 0.5) +
  facet_wrap_paginate(~ name, ncol = 3, nrow = 3, scales = 'free', page = 4) +
  scale_fill_brewer(palette = "Pastel1")

```
Поскольку во многих переменных большое количество значений, равных 0, рой пчел в этих случаях выглядит уж очень неэстетично...

## Категориальные переменные

1) Сделайте подходящие визуализации категориальных переменных. Обоснуйте, почему выбрали именно этот тип.

```{r}

cleaned_data %>%
  ggplot(aes(x = Category, fill = Category)) +
  geom_bar() +
  theme_bw()

```
Для визуализации переменной Category была выбрана столбчатая диаграмма, т.к. этот тип подходит для отображения частот для категорий и их сравнения между собой.

# Статистические оценки

## Проверка на нормальность

1) Оцените каждую переменную на соответствие нормальному распределению с помощью теста Шапиро-Уилка. Какие из переменных являются нормальными и как как вы это поняли?

```{r}

cleaned_data %>%
  summarize(across(where(is.numeric), ~shapiro.test(.x)$p.value)) %>%
  pivot_longer(everything()) %>%
  rename(`Переменная` = name, `p-value` = value) %>%
  filter(`p-value` >= 0.05)

```
Для всех количественных переменных при использовании теста Шапиро-Уилка р < 0.05, т.е. для всех переменных распределения отличные от нормального.

2) Постройте для каждой количественной переменной QQ-плот. Отличаются ли выводы от теста Шапиро-Уилка? Какой метод вы бы предпочли и почему?

```{r}

for (col in 4:ncol(cleaned_data)) {
  qqnorm(cleaned_data[[col]])
  qqline(cleaned_data[[col]])
}

```

Выводы не отличаются. Я бы предпочла тест Шапиро-Уилка, т.к. при его использовании мы получаем числа, которые можно отфильтровать по необходимым условиям (нет необходимости визуально оценивать график для каждой переменной)

3) Ниже напишите, какие ещё методы проверки на нормальность вы знаете и какие у них есть ограничения.

Визуальная оценка гистограммы: могут быть неоднозначности в интерпретации, зависит от параметров графика. Тест Колмогорова-Смирнова: чувствителен к размеру выборки (лучше работает на больших выборках).


## Сравнение групп

1) Сравните группы (переменная **Category**) по каждой переменной (как количественной, так и категориальной). Для каждой переменной выберите нужный критерий и кратко обоснуйте его выбор в комментариях.

```{r}

ziw_calc <- function(x) {
  ziw(x[cleaned_data$Category == 'Rice'], x[cleaned_data$Category == 'Cookie'], perm = T)$p.value
}

ziw_values <- c()
for (col in 4:ncol(cleaned_data)) {
  ziw_values <- append(ziw_values, ziw_calc(cleaned_data[[col]]))
}
ziw_values <- ziw_values %>% as.data.frame() %>% t()
colnames(ziw_values) <- colnames(cleaned_data[4:ncol(cleaned_data)])
ziw_values

```
В связи с отличным от нормального распределением хотела использовать тест Манна-Уитни, но не уверена, насколько можно его использовать при большом количестве нулевых значений. Поэтому попробовала использовать Zero-Inflated Rank Test.
По результатам этого теста категории Rice и Cookie статистически значимо отличаются по всем количественным переменным, кроме Beta Cryptoxanthin, Cholesterol, Sodium  Zinc.

# Далее идут **необязательные** дополнительные задания, которые могут принести вам дополнительные баллы в том числе в случае ошибок в предыдущих

## Корреляционный анализ

1) Создайте корреляционную матрицу с визуализацией и поправкой на множественные сравнения. Объясните, когда лучше использовать корреляционные матрицы и в чём минусы и плюсы корреляционных исследований.

```{r}

cleaned_data %>% 
  select(where(is.numeric)) %>% 
  cor(method = "spearman") %>% 
  corrplot()

cleaned_data %>% 
  select(where(is.numeric)) %>%
  corr.test(adjust = "bonferroni", method = "spearman")

```
Корреляционные матрицы можно использовать, когда необходимо изучить связь между переменными.
Плюсы:
- Позволяют оценить степень и направление связи между переменными.
- Могут помочь отобрать наиболее важные переменные для дальнейшего анализа и наоборот, исключить переменные со слабой связью.
Минусы:
- Корреляция необязательно означает причинно-следственную связь.
- В больших датасетах может быть ложная корреляция.
- Не учитываются другие факторы, которые могут влиять на связь между переменными.

## Моделирование

1) Постройте регрессионную модель для переменной **Category**. Опишите процесс построения

```{r}

glm(cleaned_data$Category ~ ., cleaned_data[,-c(1:3)], family = binomial) %>% 
  step() %>%
  summary()

```

Вначале с использованием функции glm построили модель логистической регрессии для переменной Category с включением всех количественных переменных, затем добавили функцию step(), которая пошагово подобрала комбинацию предикторов для получения наиболее надежной модели. И, наконец, функцией summary() вывели характеристики итоговой модели.


